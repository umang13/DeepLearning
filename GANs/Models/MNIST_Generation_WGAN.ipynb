{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "#import PIL\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "#import imageio\n",
    "from IPython import display\n",
    "print(tf.__version__)\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 11:31:07.826905 4719961536 training.py:1952] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "W0919 11:31:11.599653 4719961536 training.py:1952] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss : -11.024621963500977 , Generator loss : 0.18237659335136414\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD0AAAA9CAYAAAAeYmHpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKAklEQVRoge2ae0zP/xfHH7kUipAPXb+KXHIt1xBzGVZzmdtcZ9ZG2BiGuc7GaI0/GDMzs5TcapO5zv0+TK6VlCiULpQSReH7x3vnvBV9fvjnu/0+n/NPeL97e533Oed5nud53g7fv3/H1qzOf32A/8LsTtuK2Z22FbNJp+tZu7h//37tZ46OjgDUrVsXgPr16wNQWlpKkyZNAMjPzwfAzc1Nr7u6ugJQXFysf3/79m21Z9WtW5c6dYz3//Hjx2rXmjVrxtevXwH48OGDPkPOU1RUBEBlZaWeS+6fMGGCwx87LQcBqKqqAqB58+Y/He7Zs2fVHHR0dOTz58/VniWHcnFx4d27dwAUFBQA8PnzZ1q3bg3AzZs3Aejbty8ATk5OvHjxAoDU1FQAgoKCePnyJQBNmzYF4NOnTwB4enryv7iHVacdHIwX5efnR1ZWFgBfvnwBICcnR+9xc3MDoEOHDgDk5eXRokULAMrLywF49eoVYLw0cbp9+/YAeHh4qBPe3t4A9OvXD4Br167x7ds3dRbAYrFoJslPeckODg60bNnSqtP2mq7N7t69q+lWWloKwIABAwBITExkzJgxAJrm5eXlJCQkALBnzx4A0tLSAHj37h33798HoHfv3gDs3r0bJycnAE3lgIAAAN6+fYuPjw8ASUlJAMyaNYtr164BMHDgQABu3boFGFnZsGFDq/7YZKQdrBX98ePHvwMUFhbi7OwMmDXq4uICGABSUVEBoKhpsVi4e/cugNZ7u3btAPj27ZvWrzwjJCREkf/MmTOAmQVlZWV4eXlVO1dubq6CoACrANqP6D127NhfordNRvq30BtMdPTw8ADgyZMngFGjfn5+gIm82dnZ3Lt3D4Dx48f/9PtXr14FzJb48OFDBg8eDJiRlhaWkpJCo0aNADh79ixgZEZKSgoAXbp0AeDUqVMABAcHa4cZO3bsr/2ylt6HDh36DgZA+fr6AugB5MFgEAiA58+fA9CiRQt1Ul5EXl4eAO7u7nrtn3/+AYzeLC9TerGkflVVlba2ixcvAjB06FDlDfJTANbb25unT58CEBERYU9vMavp3aBBA/2zANGWLVsAmDZtGgDJycm0atUKMKP/6tUrLY3g4GDAzIJ79+5pW5o6dSpg0EsBvuzsbAAiIyMBWLFihYLVgQMHAKNlHT58GIARI0YAZuoPGjRIn1Gb2SNd036sy9zcXMB8s8KlfwQyiX50dDSPHz8GoHv37oBJIho0aEBsbCyAUlt/f3+NpgwQcm316tXaLufMmQMYGBMSEqL/P6BtraCggMmTJ/+9040bN9YHC5j06tULgOPHjwMGist98fHxgDGMZGRkACaqlpWVAQbyCrLLdHblyhWWLVsGwIYNGwAUOF1dXfU+QWxXV1dCQ0MB2LlzJ4C+yNjYWEpKSqw6bZPpbbVlyTzdtm1bZTmFhYWAOVpmZWXRv39/AM6fPw8Y/Ldnz56A2YIEyEaMGKFTk/TYY8eO0blzZwAuXLgAmNOTm5ubsrofJzFpUTLN3b59GzBG0tevXwMQHh5ub1liVmtaiEhycrIqFW/evAGgY8eOgMF9pV7fv38PGJPSyZMnAZg/fz5gAlRycjLXr18HYPHixYAxM8szTpw4Ue3akSNHWLNmDQCXL18GIDAwkI0bNwKwfft2wJzvnZycFERrM5uM9G/VdGVlpepTkyZNAtC3WVxcrPOu0NFmzZopPUxMTATMdpaamqrtSGhop06dNBMkgqNHjwaMmhY0Flzw8/PTllmvnpGsggEuLi46sU2ZMuXPNTLhv9nZ2ap/SfoJgGzdupWJEycC0KZNG8DQzQ4dOgTAyJEjAVi5ciUA/fv3V+lIgCkgIEAdEzYlTr148ULHyF27dgGwefNm1dKGDRsGQFRUFABLly5Vnl+b2WR6W420CAaurq46BgpR8PT0BCAmJkajKiAXEBCgiqS0LmkpvXv3VuFO+Pm+ffu0NBYtWgSg92RkZKg0JcwsPz+fQYMGASbfl7bm7OysGVqb2SNd06Rl5efna8ROnz4NoARj06ZNLFiwADDbRlpaWjXxHYw5GoyWJROR1OGZM2eUox87dgyAHTt2AJCQkKB1LuLi8uXLiYmJAUxuL8sBMOu8NvstEeHly5d06tQJMBFXnImMjFTlUphZXl6ejqXCy2UgSElJ+UkN9fX11Q6wbt06wCyjoKAg+vTpA8ClS5cAo7Tk36RLyIv08PDQTjNq1Cg7IxOzmt4WiwWA169fa5sR1iUtLCMjgyFDhgDmFqO4uJjNmzcDMHPmTMAEoUaNGpGZmQmYYBgdHU14eDiAZoEIDCkpKdom4+LiANi7dy/r168HzGlMRIWoqCi77v0rsxppmVZEmQRT25aNxOzZszXqAnITJ05UIiGAJty9VatW2r5EpHB0dNTd1fTp0wFzL3b79m1lZ7LLql+/voKVMLKIiAjA0OGF8dVm9kjXNKmN1NRUJQOC9hLBjIwMFf8kOk2aNNGoi7x0584dADIzM5V+ChFJSkrSPdW8efMAePDgAWDIP0I8RAIOCwvj3LlzAEyYMAEwKW1OTo4i/185Lb1vyJAhmur+/v56GDBahvTzwMBAACoqKlQ3kwW8MCwvLy/GjRtX7aCxsbHackQukgFk2rRpP62UPD09td1JaclZ/fz8tJ3VZvb0rmnyFqXFgKlSSjs7d+6c8maRfwoKCjRdBXykBGJiYlREEHVzyZIlzJ07FzDWtmCWRVxcHEOHDgVg7dq1AISHh6uIcePGjWq/t2nTJo4ePQqYQkRNs8lIW6Wh8fHxelF2UkJAhA/7+/urSCcZ0bVrV/2wRrJA7nd3d9cWKLTy06dPjBo1CjBrU+SjzMxMzark5GTAEB0EA6R1CbB6eXkpgRo/fvyfiwhy4KSkJB0whDEJaG3bto2FCxcCZl8fPny4rn9WrVoFmMDXvn171bVkARAcHKxoLeqIlEN6ejrdunUDTGG/adOm6qToZrKfrqioUO5dm9lkeluNtKRYSUmJbjiEWcmbDg0NVXlmxowZgMHaZDcsPVYinp2drZGTZ/r4+Oj0JoKEtMawsDDdiEjJFBUV6XUBNCkxR0dHevToYdVpe6RrmhCK1q1b69c7wrllTnZ2dtZ6Fx58/vx5/VJBWtbBgwcBA6iEe8tMnp+fr5EWvVza365du/TPUu9hYWGkp6cDJniKVDVmzBjdqojwUdPska5pIstaLBaNrNSORHfgwIGqgcueKyAgQNFXIiCrWIvFogt+UUsEJwD9Jk2UGicnp2rbFDD4/4/zOZjKTElJiSL5Xzkto19BQYF+eynyjKTy48ePlbkJ4Hh7e2uKyRAiauqjR4/UITncgwcP9PCyyJP2VF5erixQPt0qLCzUlJeVsGhwJSUldjX0V2aVkf2/mk1G2u60rZjdaVsxm3T6X05ipASoGoYlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<BatchDataset shapes: ((128, 28, 28, 1), (128, 10)), types: (tf.float32, tf.float32)>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5aef9ec75455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mw_cond_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_Cond_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mw_cond_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-5aef9ec75455>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, images, labels, epochs, batch_size)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;31m#    x_train = x_train.take(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimages_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \"\"\"\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2285\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2286\u001b[0;31m       \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[0mbatched_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mprepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"component_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1098\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1099\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1100\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<BatchDataset shapes: ((128, 28, 28, 1), (128, 10)), types: (tf.float32, tf.float32)>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "class W_Cond_GAN :\n",
    "    \n",
    "    def __init__(self, img_width, img_height, img_channels, num_classes):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.img_channels = img_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.noise_dim = 100\n",
    "        self.clip_value = 0.01\n",
    "        self.disc_train_count = 5\n",
    "        self.discriminator = self.discriminator_model()\n",
    "        self.discriminator.compile(optimizer=RMSprop(lr=0.0001), loss=self.wasserstein_loss)\n",
    "\n",
    "        self.generator = self.generator_model()\n",
    "        noise = Input(shape=(self.noise_dim,))\n",
    "        labels = Input(shape=(self.num_classes,))\n",
    "        img_generated = self.generator([noise, labels])\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        gan_output = self.discriminator([img_generated, labels])\n",
    "        self.gan_model = Model(inputs=[noise, labels], outputs=gan_output)\n",
    "        self.gan_model.compile(optimizer=RMSprop(lr=0.0001), loss=self.wasserstein_loss)\n",
    "        \n",
    "\n",
    "\n",
    "    def generator_model(self):\n",
    "        input_noise = Input(shape=(self.noise_dim,), name='Z_noise')\n",
    "        class_labels = Input(shape=(self.num_classes), name='Y')\n",
    "        merged_input = Concatenate()([input_noise, class_labels])\n",
    "\n",
    "        hidden_vals = Dense(7*7*256)(merged_input)\n",
    "        hidden_vals = BatchNormalization()(hidden_vals)\n",
    "        hidden_vals = LeakyReLU()(hidden_vals)\n",
    "        hidden_vals = Reshape((7,7,256))(hidden_vals)\n",
    "\n",
    "        hidden_vals = Conv2DTranspose(128, (5,5), strides=(1,1), padding='same')(hidden_vals)\n",
    "        hidden_vals = BatchNormalization()(hidden_vals)\n",
    "        hidden_vals = LeakyReLU()(hidden_vals)\n",
    "\n",
    "        hidden_vals = Conv2DTranspose(64, (5,5), strides=(2,2), padding='same')(hidden_vals)\n",
    "        hidden_vals = BatchNormalization()(hidden_vals)\n",
    "        hidden_vals = LeakyReLU()(hidden_vals)\n",
    "\n",
    "        outputs = Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', activation='tanh')(hidden_vals)\n",
    "\n",
    "        model = Model(inputs=[input_noise, class_labels], outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        input_image = Input(shape=(self.img_height, self.img_width, self.img_channels,), name='X')\n",
    "        class_labels = Input(shape=(self.num_classes,), name='Y')\n",
    "\n",
    "        hidden_vals = Conv2D(64, (5,5), strides=(2,2), padding='same')(input_image)\n",
    "        hidden_vals = LeakyReLU()(hidden_vals)\n",
    "        hidden_vals = Dropout(0.3)(hidden_vals)\n",
    "\n",
    "        hidden_vals = Conv2D(128, (5,5), strides=(2,2), padding='same')(hidden_vals)\n",
    "        hidden_vals = BatchNormalization()(hidden_vals)\n",
    "        hidden_vals = LeakyReLU()(hidden_vals)\n",
    "        hidden_vals = Dropout(0.3)(hidden_vals)\n",
    "\n",
    "        hidden_vals = Flatten()(hidden_vals)\n",
    "\n",
    "        merged_with_labels = Concatenate()([hidden_vals, class_labels])\n",
    "        merged_with_labels = Dense(256, activation='relu')(merged_with_labels)\n",
    "        outputs = Dense(1)(merged_with_labels)\n",
    "\n",
    "        model = Model(inputs=[input_image, class_labels], outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def wasserstein_loss(self, pred, truth):\n",
    "        return K.mean(truth * pred)\n",
    "    \n",
    "    def clip_gradients(self, model, clip_value):\n",
    "        for layer in model.layers :\n",
    "                    weights = layer.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    layer.set_weights(weights)\n",
    "        return model\n",
    "    \n",
    "    # Generates a tensor sampled from a random normal distribution\n",
    "    def generate_uniform_noise(self, batch_size) :\n",
    "        return tf.random.normal([batch_size, self.noise_dim],dtype=tf.dtypes.float32)\n",
    "    \n",
    "    def one_hot_encode(self, y):\n",
    "        return tf.reshape(tf.one_hot(y, self.num_classes), (1,self.num_classes))\n",
    "    \n",
    "    def generate_img(self, input_noise, input_label, epoch) :\n",
    "        label_vector = self.one_hot_encode(input_label)\n",
    "        predictions = self.generator.predict([input_noise,label_vector])\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.savefig(\"img_at_epoch_{}.png\".format(epoch))\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_sample_labels(self, batch_size):\n",
    "        sampled_labels = np.random.randint(0, self.num_classes, batch_size)\n",
    "        return np.array([self.one_hot_encode(x) for x in sampled_labels]).reshape(-1,self.num_classes,)\n",
    "    \n",
    "    def train(self, images, labels, epochs, batch_size) :\n",
    "        buffer_size = images.shape[0]\n",
    "        random_fixed_noise = self.generate_uniform_noise(1)\n",
    "        # Reshape to account for greyscales and normalize RGB to [-1,1] as per GoodFellow 2016\n",
    "        x_train = images.reshape(images.shape[0], 28, 28, 1).astype('float32')\n",
    "        x_train = (x_train - 127.5)/127.5\n",
    "        y_train = to_categorical(labels, 10)\n",
    "        for t in range(epochs):\n",
    "            start = time.time()\n",
    "            x_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "        #    x_train = x_train.take(5)\n",
    "            for images_mini_batch, labels in x_train :\n",
    "#                 for train_iter in range(self.disc_train_count) :\n",
    "                noise = self.generate_uniform_noise(batch_size)\n",
    "                generated_images = self.generator.predict([noise, labels])\n",
    "\n",
    "                discr_real_loss = self.discriminator.train_on_batch([images_mini_batch, labels], np.ones((batch_size,1)))\n",
    "                discr_fake_loss = self.discriminator.train_on_batch([generated_images, labels], -1 * np.ones((batch_size,1)))\n",
    "                self.discriminator = self.clip_gradients(self.discriminator, self.clip_value)\n",
    "                    \n",
    "            random_labels = self.generate_sample_labels(batch_size)\n",
    "            gen_loss = self.gan_model.train_on_batch([noise, random_labels], np.ones((batch_size,1)))\n",
    "            print(\"Discriminator loss : {} , Generator loss : {}\".format(discr_real_loss + discr_fake_loss, gen_loss))\n",
    "            self.generate_img(random_fixed_noise, 1, t)\n",
    "            \n",
    "    \n",
    "                \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "img_width, img_height = x_train[0].shape\n",
    "num_classes = 10 \n",
    "w_cond_gan = W_Cond_GAN(img_width, img_height, 1, num_classes)\n",
    "w_cond_gan.train(x_train, y_train, 10, 128)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate numbers from the trained generator now\n",
    "num_to_generate = 0\n",
    "random_fixed_noise = w_cond_gan.generate_uniform_noise(1)\n",
    "w_cond_gan.generate_img(random_fixed_noise,num_to_generate, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(10, 1), dtype=float32) tf.Tensor([[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sampled_labels = np.random.randint(0, 10, 128)\n",
    "labels_sampled = tf.convert_to_tensor(np.array([w_cond_gan.one_hot_encode(x) for x in sampled_labels]).reshape(-1,10,1))\n",
    "print(labels_sampled[1] , w_cond_gan.one_hot_encode(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
