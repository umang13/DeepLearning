{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "#import PIL\n",
    "import glob\n",
    "\n",
    "#import imageio\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid,save_image\n",
    "from IPython import display\n",
    "from torchvision import datasets, transforms\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_channels = 1\n",
    "num_classes = 10\n",
    "noise_dim = 100\n",
    "clip_value = 0.01\n",
    "train_ratio = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module) :\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dense1 = nn.Sequential(nn.Linear(noise_dim + num_classes, 4*4*512),\n",
    "                                    nn.BatchNorm1d(4*4*512), nn.LeakyReLU(0.2))\n",
    "        self.conv_trans1 = nn.Sequential(nn.ConvTranspose2d(512, 256, (3,3), stride=(2,2), padding=1),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.LeakyReLU(0.2),)\n",
    "        self.conv_trans2 = nn.Sequential(nn.ConvTranspose2d(256, 128, (4,4), stride=(2,2), padding=1),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.LeakyReLU(0.2),)\n",
    "        self.conv_trans3 = nn.Sequential(nn.ConvTranspose2d(128, 1, (4,4), stride=(2,2), padding=1),\n",
    "                                        nn.Tanh(),)\n",
    "#         noise = Input(shape=(self.noise_dim,))\n",
    "#         labels = Input(shape=(self.num_classes,))\n",
    "#         img_generated = self.generator([noise, labels])\n",
    "        \n",
    "#         self.discriminator.trainable = False\n",
    "        \n",
    "#         gan_output = self.discriminator([img_generated, labels])\n",
    "#         self.gan_model = Model(inputs=[noise, labels], outputs=gan_output)\n",
    "#         self.gan_model.compile(optimizer=RMSprop(lr=0.0001), loss=self.wasserstein_loss)\n",
    "    def forward(self, input_noise, labels):\n",
    "        labels = labels.float()\n",
    "        x_ = self.dense1(torch.cat((input_noise, labels),1))\n",
    "        x_ = self.conv_trans1(x_.view(x_.shape[0], 512, 4, 4))\n",
    "        x_ = self.conv_trans2(x_)\n",
    "        x_ = self.conv_trans3(x_)\n",
    "        return x_\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Discriminator(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 64, (4,4), stride=(2,2), padding=1),\n",
    "                                  nn.LeakyReLU(0.2),\n",
    "                                  nn.Dropout2d(0.3),)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, (3,3), stride=(2,2), padding=1),\n",
    "                                   nn.BatchNorm2d(128),\n",
    "                                  nn.LeakyReLU(0.2),\n",
    "                                  nn.Dropout(0.3),)\n",
    "        self.dense1 = nn.Sequential(nn.Linear(6282, 256),\n",
    "                                   nn.LeakyReLU(0.2),\n",
    "                                   nn.Linear(256,1),)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_images, labels):\n",
    "        labels = labels.float()\n",
    "        x_ = self.conv1(input_images)\n",
    "       # print(x_.shape)\n",
    "        x_ = self.conv2(x_)\n",
    "        #print(x_.shape)\n",
    "        x_ = x_.view(x_.shape[0],-1)\n",
    "        #print(x_.shape)\n",
    "        x_ = torch.cat((x_, labels), 1)\n",
    "        #print(x_.shape)\n",
    "        x_ = self.dense1(x_)\n",
    "        return x_\n",
    "        \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_noise(noise_size, batch_size) :\n",
    "    return torch.randn(batch_size, noise_size)\n",
    "\n",
    "def wasserstein_loss(pred, truth) :\n",
    "    return torch.mean(truth * pred)\n",
    "\n",
    "def clip_gradients(model, clip_limit):\n",
    "    for p in model.parameters():\n",
    "                    p.data.clamp_(-clip_limit, clip_limit)\n",
    "            \n",
    "\n",
    "def get_sample_image(G, n_noise=100):\n",
    "    \"\"\"\n",
    "        save sample 100 images\n",
    "    \"\"\"\n",
    "    img = np.zeros([280, 280])\n",
    "    for j in range(10):\n",
    "        c = torch.zeros([10, 10]).to(device)\n",
    "        c[:, j] = 1\n",
    "        z = torch.randn(10, n_noise).to(device)\n",
    "        y_hat = G(z,c).view(10, 28, 28)\n",
    "        result = y_hat.cpu().data.numpy()\n",
    "        img[j*28:(j+1)*28] = np.concatenate([x for x in result], axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "Discriminator loss : -0.3004552721977234 , Generator loss : -0.00905001163482666\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.19726793467998505 , Generator loss : 0.13129985332489014\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.15004754066467285 , Generator loss : 0.27197736501693726\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.09402923285961151 , Generator loss : 0.035656217485666275\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.04907269775867462 , Generator loss : -0.05336248129606247\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.059706300497055054 , Generator loss : -0.02963740937411785\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.03410840034484863 , Generator loss : 0.03056771121919155\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.050747767090797424 , Generator loss : -0.18606796860694885\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.00853574275970459 , Generator loss : 0.17838357388973236\n",
      "torch.Size([10])\n",
      "Discriminator loss : -0.035808928310871124 , Generator loss : -0.06547760963439941\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "\n",
    "discriminator_optimizer = torch.optim.RMSprop(discriminator.parameters(), lr=learning_rate)\n",
    "generator_optimizer = torch.optim.RMSprop(generator.parameters(), lr=learning_rate)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST(root='../data/', train=True, download=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "true_image = torch.FloatTensor([1])\n",
    "fake_image = true_image * -1\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "epochs = 10\n",
    "for epoch in range(epochs) :\n",
    "    for index, (images_mini_batch, labels) in enumerate(trainloader) :\n",
    "        images_mini_batch.to(device)\n",
    "        true_image.to(device)\n",
    "        fake_image.to(device)\n",
    "        labels = F.one_hot(labels, num_classes)\n",
    "        labels.to(device)\n",
    "        if(index == 0) :\n",
    "            print(labels[0].shape)\n",
    "        \n",
    "        noise = generate_random_noise(noise_dim, batch_size)\n",
    "        noise.to(device)\n",
    "        \n",
    "        discriminator_optimizer.zero_grad()\n",
    "        disc_real_outputs = discriminator(images_mini_batch, labels)\n",
    "        disc_fake_outputs = discriminator(generator(noise, labels), labels)\n",
    "        total_disc_loss = wasserstein_loss(disc_real_outputs, true_image) + wasserstein_loss(disc_fake_outputs, fake_image)\n",
    "        \n",
    "        total_disc_loss.backward()\n",
    "        \n",
    "        discriminator_optimizer.step()\n",
    "        clip_gradients(discriminator, clip_value)\n",
    "        generator_optimizer.zero_grad()\n",
    "        \n",
    "        if(index % 5 == 0) :\n",
    "            gen_noise = generate_random_noise(noise_dim, batch_size)\n",
    "            gen_outputs = generator(gen_noise, labels)\n",
    "            gen_loss = wasserstein_loss(discriminator(gen_outputs, labels), true_image)\n",
    "            gen_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "    print(\"Discriminator loss : {} , Generator loss : {}\".format(total_disc_loss, gen_loss))\n",
    "    save_image(gen_outputs.data[0], \"./images/%d.png\" % epoch, nrow=1, normalize=True)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def wasserstein_loss(self, pred, truth):\n",
    "        return K.mean(truth * pred)\n",
    "    \n",
    "    def clip_gradients(self, model, clip_value):\n",
    "        for layer in model.layers :\n",
    "                    weights = layer.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    layer.set_weights(weights)\n",
    "        return model\n",
    "    \n",
    "    # Generates a tensor sampled from a random normal distribution\n",
    "    def generate_uniform_noise(self, batch_size) :\n",
    "        return tf.random.normal([batch_size, self.noise_dim],dtype=tf.dtypes.float32)\n",
    "    \n",
    "    def one_hot_encode(self, y):\n",
    "        return tf.reshape(tf.one_hot(y, self.num_classes), (1,self.num_classes))\n",
    "    \n",
    "    def generate_img(self, input_noise, input_label, epoch) :\n",
    "        label_vector = self.one_hot_encode(input_label)\n",
    "        predictions = self.generator.predict([input_noise,label_vector])\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.savefig(\"model1_img_at_epoch_{}.png\".format(epoch))\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_sample_labels(self, batch_size):\n",
    "        sampled_labels = np.random.randint(0, self.num_classes, batch_size)\n",
    "        return tf.convert_to_tensor(np.array([self.one_hot_encode(x) for x in sampled_labels]).reshape(-1,self.num_classes,))\n",
    "    \n",
    "    def train(self, images, labels, epochs, batch_size) :\n",
    "        buffer_size = images.shape[0]\n",
    "        random_fixed_noise = self.generate_uniform_noise(1)\n",
    "        # Reshape to account for greyscales and normalize RGB to [-1,1] as per GoodFellow 2016\n",
    "        x_train = images.reshape(images.shape[0], 28, 28, 1).astype('float32')\n",
    "        x_train = (x_train - 127.5)/127.5\n",
    "        y_train = to_categorical(labels, self.num_classes)\n",
    "        x_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "        for t in range(epochs):\n",
    "            start = time.time()\n",
    "       #     .take(self.disc_train_count)\n",
    "            for images_mini_batch, labels in x_train:\n",
    "                for _ in range(self.disc_train_count):\n",
    "                    noise = self.generate_uniform_noise(batch_size)\n",
    "                    generated_images = self.generator.predict([noise, labels])\n",
    "\n",
    "                    discr_real_loss = self.discriminator.train_on_batch([images_mini_batch, labels], np.ones((batch_size,1)))\n",
    "                    discr_fake_loss = self.discriminator.train_on_batch([generated_images, labels], -1 * np.ones((batch_size,1)))\n",
    "                    self.discriminator = self.clip_gradients(self.discriminator, self.clip_value)\n",
    "                    \n",
    "                random_labels = self.generate_sample_labels(batch_size)\n",
    "                gen_loss = self.gan_model.train_on_batch([noise, random_labels], np.ones((batch_size,1)))\n",
    "            print(\"Discriminator loss : {} , Generator loss : {}\".format(discr_real_loss + discr_fake_loss, gen_loss))\n",
    "            self.generate_img(random_fixed_noise, 1, t)\n",
    "\n",
    "            \n",
    "    \n",
    "                \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "img_width, img_height = x_train[0].shape\n",
    "num_classes = 10 \n",
    "w_cond_gan = W_Cond_GAN(img_width, img_height, 1, num_classes)\n",
    "w_cond_gan.train(x_train, y_train, 100, 512)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_cond_gan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-060bf186ec13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate numbers from the trained generator now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_to_generate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom_fixed_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_cond_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_uniform_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mw_cond_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_fixed_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_to_generate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w_cond_gan' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate numbers from the trained generator now\n",
    "num_to_generate = 9\n",
    "random_fixed_noise = w_cond_gan.generate_uniform_noise(1)\n",
    "w_cond_gan.generate_img(random_fixed_noise,num_to_generate, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "sampled_labels = np.random.randint(0, 10, 128)\n",
    "#y_train = to_categorical(y_train)\n",
    "labels_sampled = np.array([w_cond_gan.one_hot_encode(x) for x in sampled_labels]).reshape(-1,10)\n",
    "print( y_train.shape, labels_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tf.Tensor([[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]], shape=(1, 10), dtype=float32)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(y_train[0])\n",
    "print(w_cond_gan.one_hot_encode(y_train[0]))\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(w_cond_gan.generate_sample_labels(128)[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "true_image = torch.FloatTensor([1])\n",
    "fake_image = true_image * -1\n",
    "print(true_image.shape, fake_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 100])\n",
      "torch.Size([9, 9])\n",
      "tensor([[ 1.1845e+00, -1.0773e+00, -8.7932e-01,  1.5088e+00,  9.9296e-01,\n",
      "          8.6638e-01, -1.3979e+00, -5.4746e-01,  1.4257e+00, -1.1504e+00,\n",
      "         -4.4333e-01, -4.2188e-01,  2.0185e-01, -5.9029e-01, -1.0240e+00,\n",
      "          1.4768e+00, -1.1574e+00,  1.2716e+00, -7.6203e-01,  1.0776e+00,\n",
      "          1.0588e-01,  4.7398e-01, -4.0842e-01, -1.2114e+00,  9.7274e-01,\n",
      "         -1.3814e+00,  1.3243e-01,  1.1240e+00,  1.0353e-01, -7.9471e-01,\n",
      "          5.3642e-01,  1.1856e+00,  2.4557e+00,  7.1689e-01,  1.4755e+00,\n",
      "          1.9607e+00, -2.1436e-01, -9.4985e-02, -1.8335e+00, -1.0516e+00,\n",
      "         -1.5023e+00,  1.1358e+00,  1.6882e+00, -1.8248e-01,  1.9478e+00,\n",
      "         -1.9916e-01, -1.8321e+00,  4.8991e-01,  1.3902e+00, -1.3419e+00,\n",
      "         -1.1729e+00, -2.9572e-01, -6.0050e-01,  4.2851e-01, -4.7968e-01,\n",
      "          1.0157e+00, -5.4433e-01,  1.6908e-01,  1.9551e+00, -1.2990e+00,\n",
      "          6.1643e-01,  7.9264e-01,  1.3209e+00, -1.2800e+00,  2.0515e+00,\n",
      "          8.1395e-01, -4.3483e-01,  1.9697e+00, -6.3280e-01,  2.7236e-01,\n",
      "         -1.4915e-01,  8.3036e-01, -9.6182e-01,  2.1278e+00, -6.5820e-01,\n",
      "          1.2663e+00, -2.4385e-01, -2.5799e-01,  5.8839e-02,  3.7641e-01,\n",
      "          4.2982e-01, -5.2227e-01,  3.3724e-01, -1.1681e-01, -1.3209e+00,\n",
      "          8.6565e-01, -1.8481e+00,  9.1487e-01,  2.2322e+00, -1.1990e+00,\n",
      "         -3.5601e-01, -1.6789e-01,  1.3144e+00,  5.3020e-01, -1.0051e-01,\n",
      "         -1.4682e+00, -2.1919e-01, -1.6431e+00, -4.7232e-01, -1.7738e-01,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [ 5.5480e-01,  1.8592e+00, -2.8789e-01, -2.9111e+00,  1.7335e-01,\n",
      "          2.6339e+00, -1.7032e+00,  1.0758e+00, -1.7730e+00,  6.6825e-01,\n",
      "          5.4424e-01, -2.1107e-01,  2.4034e-01, -1.0799e+00,  9.6194e-01,\n",
      "          8.8159e-02,  3.7158e-01, -3.5550e-01,  5.7809e-01, -2.0983e+00,\n",
      "         -6.0542e-01, -1.3288e+00, -5.5001e-01,  5.7672e-01, -1.3049e-01,\n",
      "         -3.7367e-01,  7.9365e-01,  5.9944e-01,  1.1758e+00, -1.2024e+00,\n",
      "         -5.5277e-01,  3.4912e-01,  5.7811e-01,  3.9159e-01,  2.1356e-01,\n",
      "         -1.3350e+00, -3.9223e-01, -5.0053e-01, -6.6689e-01, -6.1782e-01,\n",
      "          1.7790e-01, -1.9333e-01, -3.3762e-01,  2.1903e+00, -1.1662e+00,\n",
      "          2.1157e-01, -5.3571e-01,  4.2883e-01, -6.5586e-01, -1.9184e+00,\n",
      "         -1.2455e+00, -3.4854e-01,  5.3694e-01, -5.6911e-01, -7.8523e-01,\n",
      "          1.7411e+00, -4.0699e-01, -4.9557e-01,  1.3265e+00, -1.4996e+00,\n",
      "          5.3006e-01,  6.4121e-01, -9.6490e-01,  1.2412e+00,  8.4531e-01,\n",
      "          8.0058e-01,  8.8815e-01,  1.4725e+00, -6.7928e-01, -7.3361e-01,\n",
      "         -1.7484e+00, -1.2567e+00, -1.4260e+00, -8.8672e-01, -9.4796e-01,\n",
      "         -1.1746e+00,  1.1852e+00,  1.3797e+00, -1.1307e+00,  2.2935e-01,\n",
      "         -3.9169e-01, -1.4735e+00,  1.5710e+00,  6.3837e-01, -5.3349e-01,\n",
      "         -6.8790e-01, -7.8675e-01, -2.7293e-01, -8.5637e-02, -9.4077e-01,\n",
      "          6.7918e-01, -8.0735e-01,  1.2097e+00,  4.4241e-01,  1.4264e+00,\n",
      "          1.3080e+00,  7.0922e-01,  4.4518e-01, -2.4418e-01,  8.9952e-01,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [-1.6720e+00,  1.6642e+00,  3.2806e-01, -4.2228e-01, -2.7855e-01,\n",
      "          4.4271e-01, -3.4829e-01, -2.4476e+00,  8.5409e-01,  1.7745e+00,\n",
      "          4.6838e-01, -4.6960e-01, -1.1554e+00,  9.6659e-01, -1.0391e+00,\n",
      "         -8.6112e-01,  3.1258e-01,  2.5333e-01, -2.7916e-01, -5.6333e-02,\n",
      "          8.2438e-01, -1.5287e-02, -4.9668e-01, -2.0783e-01,  7.1006e-01,\n",
      "          1.1747e+00, -5.1832e-01, -3.9760e-01, -1.1279e+00, -2.1660e-01,\n",
      "          6.8563e-01,  1.4152e+00, -1.5964e-01, -8.9047e-01,  1.8603e-01,\n",
      "         -6.4229e-01,  1.9932e-01,  4.1161e-01,  1.1774e-01,  6.4631e-02,\n",
      "          2.8879e-01, -1.0907e+00,  1.1196e+00,  5.0673e-02, -1.3648e+00,\n",
      "          1.3233e+00,  1.9062e+00,  4.9157e-01, -7.7180e-01, -3.1538e-01,\n",
      "          4.4275e-02,  5.7139e-01,  2.0702e+00,  1.8285e+00, -5.9613e-01,\n",
      "         -8.4476e-01, -6.7899e-01,  6.2861e-01, -2.1862e-01, -1.1320e-01,\n",
      "          8.2139e-01,  5.4627e-01, -4.3575e-01, -1.4090e-01,  2.9309e-01,\n",
      "         -7.6921e-01,  1.2733e+00,  1.2793e-01,  1.7207e+00,  1.0993e+00,\n",
      "          8.0705e-01, -3.3509e-01, -3.2544e-02, -1.2808e+00, -1.2183e+00,\n",
      "          7.8041e-01,  8.6180e-01,  4.2879e-02,  1.9615e+00, -1.3002e+00,\n",
      "          3.7840e-01,  2.3990e-01,  9.6292e-01, -3.5650e-01,  2.4883e-01,\n",
      "          9.2243e-01, -8.3082e-01, -1.9397e-01,  8.9680e-03, -7.5816e-01,\n",
      "          4.4793e-01,  2.2894e-01,  8.4235e-01, -2.7469e-01, -7.1033e-01,\n",
      "         -2.4740e-03, -5.1871e-01, -1.3388e-01, -5.1689e-01, -1.9576e+00,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [ 3.3403e-01,  8.6569e-01,  4.7184e-01,  3.2393e-01, -3.6604e-01,\n",
      "          3.1093e-01, -1.2382e+00,  7.7559e-01, -1.7306e+00,  8.5986e-01,\n",
      "          8.4203e-01, -3.0441e-01, -5.5589e-01, -1.6153e+00, -2.9258e-01,\n",
      "          1.2826e+00, -7.1914e-01, -3.0568e-01,  1.1214e+00,  1.1968e+00,\n",
      "         -2.1211e+00,  6.7406e-01,  7.0784e-01,  4.0747e-01,  1.6685e+00,\n",
      "          1.6277e+00,  3.3028e-01, -1.3598e+00, -4.7379e-01, -5.7342e-01,\n",
      "          9.4988e-01, -1.7539e+00,  4.0050e-01, -1.1794e+00, -3.0117e+00,\n",
      "         -1.8881e-02, -3.9722e-01,  6.5286e-01, -7.6523e-01, -2.8209e+00,\n",
      "         -6.3097e-01, -7.2962e-01, -1.4954e+00,  1.7941e+00,  4.6154e-02,\n",
      "          9.6530e-01, -3.9184e-01, -2.1361e+00, -7.4535e-02, -1.9740e+00,\n",
      "          1.3947e+00,  1.9159e-01, -2.1765e+00,  9.4106e-01,  2.8131e-01,\n",
      "         -1.1500e+00, -6.1761e-01, -5.3229e-01,  3.1552e-01,  1.2948e-01,\n",
      "         -7.0302e-01, -6.9790e-01, -1.1327e+00, -3.6298e-01,  1.1406e+00,\n",
      "         -4.8768e-01,  1.3860e+00,  9.3364e-02,  1.8369e+00,  2.0376e+00,\n",
      "          1.1598e+00, -2.5968e-01, -5.1036e-01, -3.0519e-01,  3.8234e-01,\n",
      "         -1.6275e+00, -2.7871e+00, -5.9753e-01, -3.3631e-01, -1.3593e+00,\n",
      "          5.5733e-01, -8.3272e-01,  5.5714e-01, -1.1207e+00, -5.7844e-01,\n",
      "          1.8805e+00,  2.1589e+00,  3.5213e-01,  6.0958e-01,  7.6981e-02,\n",
      "         -1.0639e+00, -6.3532e-01, -2.6038e-01,  4.1531e-01,  1.0343e+00,\n",
      "         -2.7080e-01, -1.5927e+00,  6.9812e-01,  1.0504e-01, -1.0281e+00,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [ 2.7772e-01,  1.2985e+00,  1.1148e+00,  1.0999e+00, -6.5706e-01,\n",
      "          9.8874e-01, -5.4327e-01,  8.0742e-01, -4.9593e-01, -9.5038e-01,\n",
      "          6.6499e-01,  5.6369e-01, -4.2834e-01, -1.6422e-01,  3.6614e-01,\n",
      "         -9.5290e-01,  2.2258e+00, -1.4693e+00,  1.2519e-01,  1.2620e+00,\n",
      "         -3.2130e-01, -4.7776e-02,  7.1681e-01,  8.4630e-01, -1.1248e+00,\n",
      "         -4.9555e-01,  3.3428e-01,  1.0618e+00,  3.4495e-01, -9.6401e-02,\n",
      "          1.7870e+00,  7.0760e-01, -4.6613e-01, -5.5775e-01,  1.3200e-01,\n",
      "         -9.8311e-01,  1.7981e+00,  5.5530e-02, -1.7694e+00,  6.7971e-01,\n",
      "         -2.0781e-01,  3.7316e-01,  1.8064e-03, -1.0555e+00, -4.2162e-01,\n",
      "         -5.0677e-01,  7.2161e-01, -9.6111e-01, -1.8737e+00, -8.8680e-01,\n",
      "          5.1087e-01,  1.9316e+00,  2.3564e+00, -8.8237e-01, -9.8331e-01,\n",
      "         -1.0509e+00, -8.7146e-01, -1.8349e+00, -3.8757e-01,  1.1605e+00,\n",
      "         -4.4670e-01,  8.6863e-01,  1.1903e-01,  5.3846e-01, -4.1264e-01,\n",
      "          1.7040e+00, -8.1383e-03, -7.5458e-01,  9.8431e-01, -1.9471e+00,\n",
      "         -4.6556e-01, -1.4224e-01, -2.2578e-01,  4.3109e-01,  1.2801e+00,\n",
      "          1.9084e+00,  1.3630e-01, -9.0776e-01,  4.0548e-01,  7.8876e-01,\n",
      "          4.8552e-01, -6.3669e-01,  1.4131e+00,  1.2211e-01, -5.5309e-01,\n",
      "          1.1356e+00,  3.8810e-01,  6.8598e-01,  3.7098e-01, -4.4372e-01,\n",
      "         -1.6175e-01,  3.0534e-01, -1.0393e-01,  8.1049e-01,  2.0908e+00,\n",
      "          1.7239e-01, -6.6505e-02,  9.4107e-01,  2.8292e-01,  3.2280e-01,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [ 2.8836e-01, -1.5355e+00, -1.4645e-01,  7.9448e-01,  8.3729e-01,\n",
      "         -7.6351e-01,  2.1772e-01, -1.9891e+00, -7.6304e-01, -1.1451e+00,\n",
      "         -5.1222e-01, -4.2629e-01, -8.8350e-01, -5.7419e-01, -5.4797e-01,\n",
      "          6.6013e-01,  1.3074e+00, -1.1417e+00, -9.0809e-01,  1.0481e-01,\n",
      "         -7.9079e-02, -1.9939e+00,  4.7920e-01, -6.1569e-01,  6.1852e-01,\n",
      "         -1.2777e+00, -2.0741e+00, -1.3597e+00,  6.8153e-02, -5.0600e-01,\n",
      "         -2.2568e+00, -1.6827e+00,  4.1380e-01, -9.9726e-01,  3.5861e-01,\n",
      "          1.2859e+00, -3.8854e-02,  9.8668e-02,  1.6583e+00,  1.2326e+00,\n",
      "         -2.5343e+00,  6.7867e-01, -4.8091e-01,  9.2151e-01,  8.9783e-01,\n",
      "          2.0954e-01,  1.2458e+00,  1.1496e+00, -3.1154e-01,  4.1889e-01,\n",
      "          1.2864e+00, -1.2616e+00,  3.9158e-01, -6.8655e-01,  6.8432e-01,\n",
      "          3.8202e-01, -1.6469e-01, -1.5557e+00,  1.1587e+00, -6.3493e-01,\n",
      "         -4.0564e-01, -3.1892e-01, -3.8986e-01, -8.8309e-01, -1.6538e+00,\n",
      "         -8.6566e-01, -1.9427e+00, -6.8969e-01, -1.4107e+00,  8.4942e-01,\n",
      "          3.8485e-01, -1.2570e+00,  1.0069e+00, -2.6978e-01,  1.0287e+00,\n",
      "          5.9698e-01, -1.1189e+00,  2.6008e-01, -2.3267e-01,  2.0015e+00,\n",
      "         -8.1896e-01, -1.1071e+00, -4.7249e-02,  7.5916e-01, -3.7763e-01,\n",
      "         -7.8519e-01,  6.2277e-05, -1.8875e-03, -3.4674e-01, -5.8489e-01,\n",
      "         -2.2339e-01,  5.3001e-01,  9.3689e-01,  3.5471e-01,  8.8147e-01,\n",
      "         -5.7251e-02,  3.6281e-01,  4.1674e-01, -4.7909e-01,  2.2628e+00,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [ 1.3566e+00,  1.6407e+00,  8.8584e-01,  8.1072e-01,  9.8984e-01,\n",
      "         -9.8417e-01, -1.0405e+00, -1.0436e+00,  1.7021e-01,  2.4646e-01,\n",
      "         -2.6847e+00,  9.2384e-02, -5.0115e-01, -1.8161e+00,  1.0156e-01,\n",
      "          1.6920e+00, -1.9607e-01, -1.9201e-02, -1.4038e+00, -3.8816e-01,\n",
      "          8.1698e-01, -1.0947e+00,  7.5409e-01, -7.9351e-01,  2.6811e-01,\n",
      "          8.5867e-02, -1.7434e-02, -1.9203e+00,  1.2000e+00,  1.5586e-01,\n",
      "         -1.7738e+00,  1.7012e-01,  1.3893e+00,  2.8847e-02, -7.9050e-01,\n",
      "          2.7854e-01, -1.7687e+00,  8.4529e-01,  5.9896e-02, -8.3286e-01,\n",
      "         -2.8801e-01, -4.3664e-01,  9.7381e-01, -1.9968e+00, -1.4881e+00,\n",
      "          1.4688e+00, -1.4450e+00, -2.9465e-01, -2.3670e-01,  8.4421e-01,\n",
      "         -5.5798e-01,  3.8191e-01,  1.0564e+00, -2.0991e-01,  2.0811e+00,\n",
      "          5.1414e-01,  8.1658e-02, -1.8984e+00,  6.2877e-01, -2.1849e+00,\n",
      "          5.9942e-01, -8.4329e-01, -4.3822e-01,  3.2928e-01, -4.1473e-01,\n",
      "          3.4129e-01,  2.2415e-02, -1.3275e+00, -6.7055e-02, -8.4483e-01,\n",
      "          5.0711e-01, -2.4360e-01, -4.8266e-01, -4.3375e-01,  1.3343e+00,\n",
      "         -7.1120e-01, -1.1013e+00,  6.8870e-01,  1.0268e+00, -1.9272e-01,\n",
      "          2.8198e-01, -2.0755e+00, -1.1061e+00,  7.3079e-01, -6.9823e-01,\n",
      "         -8.4981e-02,  1.2081e+00, -1.8336e+00, -6.1176e-02, -3.6048e-01,\n",
      "         -2.8419e-03, -1.1936e-01,  4.0287e-01,  1.7637e-01, -8.7318e-01,\n",
      "         -1.2487e+00,  9.3030e-01, -2.0976e-01,  1.2383e+00, -2.3704e-01,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [ 7.5673e-01,  1.2416e+00,  6.9060e-01, -1.8206e+00, -8.9490e-01,\n",
      "          3.1756e-02,  9.9846e-01, -4.4163e-01,  6.1757e-01, -1.2865e+00,\n",
      "         -2.8124e-01, -4.5920e-01,  1.0288e-01, -1.9181e+00,  2.8591e-01,\n",
      "          6.2632e-01,  5.5539e-03, -1.1917e+00, -5.9804e-01,  2.3476e+00,\n",
      "          7.4042e-01,  1.3868e-01, -1.1069e-01,  1.0155e-01, -3.5170e-01,\n",
      "         -3.8135e-01,  1.0412e+00, -4.5336e-01, -1.7679e-01, -7.2926e-01,\n",
      "         -7.5279e-03,  4.2271e-01,  2.5837e+00,  9.8364e-02,  8.3675e-02,\n",
      "         -1.4991e-01, -7.0647e-01,  2.4031e-01,  9.8635e-01, -5.0924e-01,\n",
      "          7.5338e-01,  4.1607e-02,  1.1158e+00,  6.3745e-01,  2.2488e+00,\n",
      "          8.8247e-01, -1.1643e+00, -6.4356e-02,  9.7342e-01,  4.3054e-01,\n",
      "          1.3140e+00,  6.5994e-01,  2.2832e+00,  9.8553e-01, -1.5189e+00,\n",
      "         -8.1609e-01, -3.1906e-02,  2.1472e-01, -1.4005e+00, -5.8573e-02,\n",
      "         -1.2661e-01,  1.0071e+00, -4.6751e-01, -6.7557e-01, -6.3336e-01,\n",
      "         -6.9268e-01,  2.1815e+00,  2.1090e+00,  1.1783e+00, -1.1861e+00,\n",
      "          2.1043e+00,  4.2022e-01, -8.7411e-01, -5.8372e-01, -2.5943e+00,\n",
      "         -2.0021e+00,  7.6042e-01, -1.7248e-01,  3.9004e-01,  4.6155e-01,\n",
      "          1.0856e+00,  2.2621e+00,  1.9747e-01,  8.1673e-01,  1.7689e+00,\n",
      "          6.5654e-02, -7.0612e-01, -1.4578e+00, -3.0675e-01,  6.9636e-01,\n",
      "          1.3438e+00,  1.8489e+00,  3.3655e-01, -2.0250e-01, -1.2770e+00,\n",
      "          7.8777e-01,  8.2191e-01,  8.3161e-01, -7.1228e-02,  7.5300e-02,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00],\n",
      "        [-8.7867e-01,  3.8465e-01, -1.0818e-01, -7.4525e-01,  9.3956e-01,\n",
      "         -3.8561e-01,  2.6525e-01, -2.4202e+00,  2.3583e-01,  3.3528e-01,\n",
      "         -2.3708e-01, -8.0354e-01,  8.5492e-01,  8.5813e-01,  3.2526e-03,\n",
      "         -1.5420e+00,  4.3322e-01, -6.8114e-01,  2.6522e-01, -8.1990e-02,\n",
      "          1.9990e-01, -1.5303e+00, -1.7696e+00, -3.2826e-01, -1.5340e+00,\n",
      "         -1.3992e+00,  1.9195e+00,  2.7424e+00, -4.0642e-01, -1.0092e+00,\n",
      "          2.4617e+00,  5.6294e-01, -1.0671e+00, -3.7476e-01, -1.2703e+00,\n",
      "         -2.0410e+00,  1.2635e+00, -1.3997e-02, -4.8091e-01,  9.5087e-01,\n",
      "         -1.5072e+00, -2.2796e-01,  1.1870e+00,  1.0830e+00,  1.3153e+00,\n",
      "          5.6316e-02, -1.6695e+00,  1.0187e+00, -3.5803e-01,  8.5250e-01,\n",
      "         -4.0466e-01, -3.5303e-01, -1.6852e+00, -1.1084e-01, -1.6953e+00,\n",
      "         -5.2952e-01,  3.1243e+00, -2.6026e-01,  4.1605e-01, -7.8895e-01,\n",
      "         -7.8205e-01,  8.9732e-01,  8.9483e-01,  2.2119e+00,  7.9251e-01,\n",
      "         -8.9557e-01,  2.7012e-01,  1.1550e+00,  8.8177e-01, -2.7718e-01,\n",
      "         -2.0594e-01, -3.9254e-01, -1.4248e+00, -1.3846e+00,  9.0724e-01,\n",
      "         -1.3698e-01, -1.5456e+00, -4.3099e-01, -1.3733e-01, -3.5253e-01,\n",
      "          7.1716e-01, -1.7877e+00,  3.4108e-01,  8.7949e-01,  8.6821e-01,\n",
      "          4.5837e-01,  4.2113e-02,  3.2009e-01, -1.1806e+00, -4.7921e-01,\n",
      "          1.0197e+00, -1.5194e-01, -4.4027e-01,  5.2391e-01,  2.0432e-01,\n",
      "          9.6873e-01,  1.4733e+00,  2.1905e+00,  1.2030e-02, -8.5409e-01,\n",
      "          0.0000e+00,  1.0000e+00,  2.0000e+00,  3.0000e+00,  4.0000e+00,\n",
      "          5.0000e+00,  6.0000e+00,  7.0000e+00,  8.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.randn(9, 100)\n",
    "print(z.shape)\n",
    "labels = torch.FloatTensor([np.arange(9) for x in range(9)])\n",
    "print(labels.shape)\n",
    "print(torch.cat((z, labels),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.FloatTensor(np.random.rand(10,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(10, 0, 1))\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
